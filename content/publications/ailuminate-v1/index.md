---
title: 'AILuminate v1.0: AI Risk & Reliability Benchmark / Generative AI Safety Benchmark'

authors:
  - MLCommons AI Safety Working Group
  - me

date: '2024-04-01T00:00:00Z'

publishDate: '2024-04-01T00:00:00Z'

publication_types: ['report']

publication: MLCommons AI Safety and AI Risk & Reliability Working Groups
publication_short: MLCommons

abstract: AILuminate v1.0 is a comprehensive benchmark for evaluating generative AI and chatbot safety across 12 hazard categories. This work establishes industry-standard risk taxonomies for AI safety evaluation, covering harm categories including violence, hate speech, sexual content, self-harm, illegal activities, and privacy violations. The benchmark informs safety standards including ISO/IEC 42001 and provides a foundation for evaluating frontier AI systems.

summary: Industry-standard benchmark for evaluating generative AI safety across 12 hazard categories. Coauthored with MLCommons AI Safety and AI Risk & Reliability groups.

tags:
  - AI Safety
  - Benchmark
  - Risk Assessment
  - Evaluation
  - MLCommons
  - Standards

featured: true

hugoblox:
  ids:
    arxiv: '2404.03555'

links:
  - type: preprint
    url: https://arxiv.org/abs/2404.03555
  - type: pdf
    url: https://arxiv.org/pdf/2404.03555.pdf
  - type: source
    url: https://mlcommons.org/

image:
  caption: 'AILuminate safety benchmark taxonomy'
  focal_point: ''
  preview_only: false

projects: []

slides: ""
---

AILuminate v1.0 represents a collaborative effort by the MLCommons AI Safety and AI Risk & Reliability Working Groups to establish comprehensive safety evaluation standards for generative AI systems. The benchmark provides a systematic framework for assessing risks across multiple hazard categories and has been adopted by leading organizations for safety evaluation.

Additional references:
- arXiv:2503.05731 (chatbot risk and harm taxonomy)
- Full benchmark available at mlcommons.org
