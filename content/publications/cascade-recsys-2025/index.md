---
title: 'Cascade: Human-in-the-Loop Shortcomings Can Increase the Risk of Failures in Recommender Systems'

authors:
  - me
  - Collaborators from Oxford and Amazon

author_notes:
  - 'Coauthor'

date: '2025-01-01T00:00:00Z'

publishDate: '2025-01-01T00:00:00Z'

publication_types: ['paper-conference']

publication: In *FAccTRec Workshop at ACM RecSys 2025*
publication_short: In *FAccTRec@RecSys 2025*

abstract: This paper examines how human-in-the-loop (HITL) shortcomings can increase the risk of cascade failures in recommender systems. We develop taxonomies for multi-agent and recommender system failure modes, with experimental setups demonstrating how HITL interventions can paradoxically amplify systemic risks. The work informs the design of more resilient evaluation frameworks for AI systems deployed in high-stakes environments.

summary: Human-in-the-loop shortcomings can increase the risk of failures in recommender systems. This paper develops taxonomies and experimental frameworks for understanding cascade failures in multi-agent setups.

tags:
  - Multi-Agent Systems
  - Recommender Systems
  - AI Safety
  - Cascade Failures
  - Human-in-the-Loop

featured: true

hugoblox:
  ids:
    arxiv: '2509.20099'

links:
  - type: preprint
    url: https://arxiv.org/abs/2509.20099
  - type: pdf
    url: https://arxiv.org/pdf/2509.20099.pdf

image:
  caption: 'Cascade failures in recommender systems'
  focal_point: ''
  preview_only: false

projects: []

slides: ""
---

This work represents collaboration with researchers at Oxford and Amazon, examining the critical intersection of human oversight and AI system failures in recommender systems. The research informs ongoing work on RecSys 2026 cascade failure and multi-agent experiments.
