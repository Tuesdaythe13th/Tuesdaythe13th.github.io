---
title: "Cascade" Paper Accepted at FAccTRec Workshop, ACM RecSys 2025
summary: Our research on human-in-the-loop shortcomings and cascade failures in recommender systems has been accepted at FAccTRec 2025.
date: 2025-01-10

image:
  caption: 'Cascade Failures in Recommender Systems'

authors:
  - me

tags:
  - Recommender Systems
  - Multi-Agent Systems
  - AI Safety
  - Cascade Failures
  - Human-in-the-Loop

content_meta:
  trending: true
---

Excited to announce that our paper **"Cascade: Human-in-the-Loop Shortcomings Can Increase the Risk of Failures in Recommender Systems"** has been accepted at the [FAccTRec Workshop](https://www.acm.org/) at ACM RecSys 2025 in Prague!

## The Problem

Human-in-the-loop (HITL) systems are often proposed as a solution to AI safety concerns—if we keep humans in the decision loop, surely that will prevent catastrophic failures? Our research demonstrates that the reality is more complex: **poorly designed HITL interventions can paradoxically amplify systemic risks** through cascade effects.

## Key Findings

Through collaboration with researchers at Oxford and Amazon, we:
- Developed **taxonomies for multi-agent and recommender system failure modes**
- Created **experimental frameworks** demonstrating how HITL shortcomings propagate through systems
- Identified specific **design patterns that increase cascade failure risk**
- Proposed **resilience-oriented evaluation frameworks** for HITL recommender systems

## Why This Matters

Recommender systems shape what billions of people read, watch, and buy. When these systems fail, they don't fail in isolation—failures cascade through user populations, content ecosystems, and business operations. Understanding how human oversight interacts with these dynamics is critical for building genuinely safer systems.

The research has implications for:
- **Platform Design**: How to structure human oversight to prevent cascade amplification
- **Evaluation Frameworks**: Moving beyond single-agent metrics to multi-agent resilience measures
- **Policy**: Informing regulations that recognize the complexity of HITL safety guarantees

## What's Next

This work is part of a broader research program on multi-agent systems safety. We're extending these findings for RecSys 2026, with experiments examining:
- Multi-stakeholder cascade dynamics (users, creators, platforms)
- Cross-platform cascade propagation
- Real-world deployment case studies

Looking forward to presenting in Prague and continuing conversations with the FAccT and RecSys communities!

---

**Read the preprint**: [arXiv:2509.20099](https://arxiv.org/abs/2509.20099)

**Related Projects**:
- [Agentic AI Evaluation Frameworks](/projects/agentic-evaluation/)
- [MLCommons Agentic AI Working Group](https://mlcommons.org/)
