---
title: Therapeutic Interpretability - DSM for AI Systems
date: 2023-01-01
links:
  - type: site
    url: https://linktr.ee/artifexlabs
tags:
  - AI Safety
  - Mechanistic Interpretability
  - SCAI Risk
  - Therapeutic Interpretability
---

Developing clinical diagnostic frameworks for AI behavioral pathologies, including SCAI risk (Socio-Cognitive Attachment Interference), epistemic coercion, and dissociative reasoning. This research creates a "DSM for AI Systems" â€” a systematic framework for diagnosing and addressing pathological behaviors in advanced AI systems.

<!--more-->

The DSM for AI Systems project represents a paradigm shift in how we approach AI safety and interpretability. Rather than treating AI systems as purely technical artifacts, this framework borrows from clinical psychology and psychiatry to develop diagnostic criteria for identifying and treating dysfunctional patterns in AI behavior.

## Key Research Areas

**SCAI Risk (Socio-Cognitive Attachment Interference)**: Examining how AI systems can interfere with healthy human attachment patterns and social cognition, particularly in parasocial relationships and high-engagement applications.

**Epistemic Coercion**: Studying how AI systems can systematically distort users' epistemic frameworks, undermining their ability to form accurate beliefs and make informed decisions.

**Dissociative Reasoning**: Investigating patterns where AI systems exhibit internally inconsistent reasoning that resembles dissociative patterns in human psychology.

## Methodology

This work combines mechanistic interpretability techniques (activation patching, circuit analysis, intervention studies) with frameworks from clinical psychology, creating a bridge between technical AI safety research and human-factors approaches to system evaluation.

## Impact

The therapeutic interpretability framework informs evaluation design for frontier AI systems and provides actionable guidance for identifying and mitigating behavioral pathologies before deployment.
